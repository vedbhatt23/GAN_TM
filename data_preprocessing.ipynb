{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: soundfile in c:\\users\\medhansh\\miniconda3\\envs\\tensorflow\\lib\\site-packages (0.12.1)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\medhansh\\miniconda3\\envs\\tensorflow\\lib\\site-packages (from soundfile) (1.15.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\medhansh\\miniconda3\\envs\\tensorflow\\lib\\site-packages (from cffi>=1.0->soundfile) (2.21)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\medhansh\\miniconda3\\envs\\tensorflow\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\medhansh\\miniconda3\\envs\\tensorflow\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install soundfile"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T14:42:52.114546900Z",
     "start_time": "2024-04-02T14:42:47.375103Z"
    }
   },
   "id": "cc1540abdbf17f3d"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12.1\n"
     ]
    }
   ],
   "source": [
    "import soundfile\n",
    "print(soundfile.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T14:42:56.180946900Z",
     "start_time": "2024-04-02T14:42:56.144434900Z"
    }
   },
   "id": "ec2eecf466d82e4e"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10.1\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "print(librosa.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T14:42:58.721179100Z",
     "start_time": "2024-04-02T14:42:58.687673500Z"
    }
   },
   "id": "991526cc84edbddb"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-02T14:45:30.762976800Z",
     "start_time": "2024-04-02T14:45:30.735299500Z"
    }
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from huggingface_hub import login\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "ds = load_dataset('google/MusicCaps')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T14:45:49.672783600Z",
     "start_time": "2024-04-02T14:45:31.454957300Z"
    }
   },
   "id": "528e05889de2428b"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['ytid', 'start_s', 'end_s', 'audioset_positive_labels', 'aspect_list', 'caption', 'author_id', 'is_balanced_subset', 'is_audioset_eval'],\n        num_rows: 5521\n    })\n})"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T14:45:49.694410800Z",
     "start_time": "2024-04-02T14:45:49.672783600Z"
    }
   },
   "id": "580f1518a786ff32"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "train_data = ds['train']\n",
    "\n",
    "# Converting to DataFrame\n",
    "df = pd.DataFrame(train_data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T14:45:50.089866Z",
     "start_time": "2024-04-02T14:45:49.689286100Z"
    }
   },
   "id": "3c91a2e1196a91ee"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "             ytid  start_s  end_s  \\\n0     -0Gj8-vB1q4       30     40   \n1     -0SdAVK79lg       30     40   \n2     -0vPFx-wRRI       30     40   \n3     -0xzrMun0Rs       30     40   \n4     -1LrH01Ei1w       30     40   \n...           ...      ...    ...   \n5516  zw5dkiklbhE       15     25   \n5517  zwfo7wnXdjs       30     40   \n5518  zx_vcwOsDO4       50     60   \n5519  zyXa2tdBTGc       30     40   \n5520  zzNdwF40ID8       70     80   \n\n                               audioset_positive_labels  \\\n0                          /m/0140xf,/m/02cjck,/m/04rlf   \n1     /m/0155w,/m/01lyv,/m/0342h,/m/042v_gx,/m/04rlf...   \n2                                   /m/025_jnm,/m/04rlf   \n3                                    /m/01g90h,/m/04rlf   \n4                                   /m/02p0sh1,/m/04rlf   \n...                                                 ...   \n5516                                /m/01sm1g,/m/0l14md   \n5517                      /m/02p0sh1,/m/04rlf,/m/06j64v   \n5518  /m/01glhc,/m/02sgy,/m/0342h,/m/03lty,/m/04rlf,...   \n5519                                /m/04rlf,/t/dd00034   \n5520                                  /m/04rlf,/m/0790c   \n\n                                            aspect_list  \\\n0     ['low quality', 'sustained strings melody', 's...   \n1     ['guitar song', 'piano backing', 'simple percu...   \n2     ['amateur recording', 'finger snipping', 'male...   \n3     ['backing track', 'jazzy', 'digital drums', 'p...   \n4     ['rubab instrument', 'repetitive melody on dif...   \n...                                                 ...   \n5516  ['amateur recording', 'percussion', 'wooden bo...   \n5517  ['instrumental music', 'arabic music', 'genera...   \n5518  ['instrumental', 'no voice', 'electric guitar'...   \n5519  ['instrumental music', 'gospel music', 'strong...   \n5520  ['glitch', 'noise', 'instrumental', 'electroni...   \n\n                                                caption  author_id  \\\n0     The low quality recording features a ballad so...          4   \n1     This song features an electric guitar as the m...          0   \n2     a male voice is singing a melody with changing...          6   \n3     This song contains digital drums playing a sim...          6   \n4     This song features a rubber instrument being p...          0   \n...                                                 ...        ...   \n5516  This audio contains someone playing a wooden b...          6   \n5517  The song is an instrumental. The song is mediu...          1   \n5518  The rock music is purely instrumental and feat...          2   \n5519  The song is an instrumental. The song is slow ...          1   \n5520  This is a glitch music piece. There is a synth...          9   \n\n      is_balanced_subset  is_audioset_eval  \n0                  False              True  \n1                  False             False  \n2                  False              True  \n3                  False              True  \n4                  False             False  \n...                  ...               ...  \n5516               False             False  \n5517                True              True  \n5518                True              True  \n5519               False             False  \n5520                True              True  \n\n[5521 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ytid</th>\n      <th>start_s</th>\n      <th>end_s</th>\n      <th>audioset_positive_labels</th>\n      <th>aspect_list</th>\n      <th>caption</th>\n      <th>author_id</th>\n      <th>is_balanced_subset</th>\n      <th>is_audioset_eval</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0Gj8-vB1q4</td>\n      <td>30</td>\n      <td>40</td>\n      <td>/m/0140xf,/m/02cjck,/m/04rlf</td>\n      <td>['low quality', 'sustained strings melody', 's...</td>\n      <td>The low quality recording features a ballad so...</td>\n      <td>4</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0SdAVK79lg</td>\n      <td>30</td>\n      <td>40</td>\n      <td>/m/0155w,/m/01lyv,/m/0342h,/m/042v_gx,/m/04rlf...</td>\n      <td>['guitar song', 'piano backing', 'simple percu...</td>\n      <td>This song features an electric guitar as the m...</td>\n      <td>0</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0vPFx-wRRI</td>\n      <td>30</td>\n      <td>40</td>\n      <td>/m/025_jnm,/m/04rlf</td>\n      <td>['amateur recording', 'finger snipping', 'male...</td>\n      <td>a male voice is singing a melody with changing...</td>\n      <td>6</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0xzrMun0Rs</td>\n      <td>30</td>\n      <td>40</td>\n      <td>/m/01g90h,/m/04rlf</td>\n      <td>['backing track', 'jazzy', 'digital drums', 'p...</td>\n      <td>This song contains digital drums playing a sim...</td>\n      <td>6</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1LrH01Ei1w</td>\n      <td>30</td>\n      <td>40</td>\n      <td>/m/02p0sh1,/m/04rlf</td>\n      <td>['rubab instrument', 'repetitive melody on dif...</td>\n      <td>This song features a rubber instrument being p...</td>\n      <td>0</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5516</th>\n      <td>zw5dkiklbhE</td>\n      <td>15</td>\n      <td>25</td>\n      <td>/m/01sm1g,/m/0l14md</td>\n      <td>['amateur recording', 'percussion', 'wooden bo...</td>\n      <td>This audio contains someone playing a wooden b...</td>\n      <td>6</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>5517</th>\n      <td>zwfo7wnXdjs</td>\n      <td>30</td>\n      <td>40</td>\n      <td>/m/02p0sh1,/m/04rlf,/m/06j64v</td>\n      <td>['instrumental music', 'arabic music', 'genera...</td>\n      <td>The song is an instrumental. The song is mediu...</td>\n      <td>1</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>5518</th>\n      <td>zx_vcwOsDO4</td>\n      <td>50</td>\n      <td>60</td>\n      <td>/m/01glhc,/m/02sgy,/m/0342h,/m/03lty,/m/04rlf,...</td>\n      <td>['instrumental', 'no voice', 'electric guitar'...</td>\n      <td>The rock music is purely instrumental and feat...</td>\n      <td>2</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>5519</th>\n      <td>zyXa2tdBTGc</td>\n      <td>30</td>\n      <td>40</td>\n      <td>/m/04rlf,/t/dd00034</td>\n      <td>['instrumental music', 'gospel music', 'strong...</td>\n      <td>The song is an instrumental. The song is slow ...</td>\n      <td>1</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>5520</th>\n      <td>zzNdwF40ID8</td>\n      <td>70</td>\n      <td>80</td>\n      <td>/m/04rlf,/m/0790c</td>\n      <td>['glitch', 'noise', 'instrumental', 'electroni...</td>\n      <td>This is a glitch music piece. There is a synth...</td>\n      <td>9</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>5521 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T14:46:36.701641600Z",
     "start_time": "2024-04-02T14:46:36.668623800Z"
    }
   },
   "id": "4f086aa1f6e6a7f"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Path to the folder containing the WAV files\n",
    "wav_folder = 'music_data'  # Update this with your actual folder path\n",
    "\n",
    "# Function to get the WAV file path based on YouTube ID\n",
    "def get_wav_path(ytid):\n",
    "    return os.path.join(wav_folder, f\"{ytid}.wav\")\n",
    "\n",
    "# Create a list to store tuples of captions and WAV file paths\n",
    "caption_wav_list = []\n",
    "\n",
    "# Iterate through the rows of the original DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    # Get the YouTube ID and caption\n",
    "    ytid = row['ytid']\n",
    "    caption = row['caption']\n",
    "    \n",
    "    # Get the WAV file path\n",
    "    wav_path = get_wav_path(ytid)\n",
    "    \n",
    "    # Append the caption and WAV file path to the list\n",
    "    caption_wav_list.append((caption, wav_path))\n",
    "\n",
    "# Create a new DataFrame from the list\n",
    "caption_wav_df = pd.DataFrame(caption_wav_list, columns=['caption', 'wav_path'])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T14:46:58.143065300Z",
     "start_time": "2024-04-02T14:46:57.917414100Z"
    }
   },
   "id": "d53b5176e3726f1a"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                caption  \\\n0     The low quality recording features a ballad so...   \n1     This song features an electric guitar as the m...   \n2     a male voice is singing a melody with changing...   \n3     This song contains digital drums playing a sim...   \n4     This song features a rubber instrument being p...   \n...                                                 ...   \n5516  This audio contains someone playing a wooden b...   \n5517  The song is an instrumental. The song is mediu...   \n5518  The rock music is purely instrumental and feat...   \n5519  The song is an instrumental. The song is slow ...   \n5520  This is a glitch music piece. There is a synth...   \n\n                               wav_path  \n0     D:\\TTM\\music_data\\-0Gj8-vB1q4.wav  \n1     D:\\TTM\\music_data\\-0SdAVK79lg.wav  \n2     D:\\TTM\\music_data\\-0vPFx-wRRI.wav  \n3     D:\\TTM\\music_data\\-0xzrMun0Rs.wav  \n4     D:\\TTM\\music_data\\-1LrH01Ei1w.wav  \n...                                 ...  \n5516  D:\\TTM\\music_data\\zw5dkiklbhE.wav  \n5517  D:\\TTM\\music_data\\zwfo7wnXdjs.wav  \n5518  D:\\TTM\\music_data\\zx_vcwOsDO4.wav  \n5519  D:\\TTM\\music_data\\zyXa2tdBTGc.wav  \n5520  D:\\TTM\\music_data\\zzNdwF40ID8.wav  \n\n[5521 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>caption</th>\n      <th>wav_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The low quality recording features a ballad so...</td>\n      <td>D:\\TTM\\music_data\\-0Gj8-vB1q4.wav</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>This song features an electric guitar as the m...</td>\n      <td>D:\\TTM\\music_data\\-0SdAVK79lg.wav</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a male voice is singing a melody with changing...</td>\n      <td>D:\\TTM\\music_data\\-0vPFx-wRRI.wav</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>This song contains digital drums playing a sim...</td>\n      <td>D:\\TTM\\music_data\\-0xzrMun0Rs.wav</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>This song features a rubber instrument being p...</td>\n      <td>D:\\TTM\\music_data\\-1LrH01Ei1w.wav</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5516</th>\n      <td>This audio contains someone playing a wooden b...</td>\n      <td>D:\\TTM\\music_data\\zw5dkiklbhE.wav</td>\n    </tr>\n    <tr>\n      <th>5517</th>\n      <td>The song is an instrumental. The song is mediu...</td>\n      <td>D:\\TTM\\music_data\\zwfo7wnXdjs.wav</td>\n    </tr>\n    <tr>\n      <th>5518</th>\n      <td>The rock music is purely instrumental and feat...</td>\n      <td>D:\\TTM\\music_data\\zx_vcwOsDO4.wav</td>\n    </tr>\n    <tr>\n      <th>5519</th>\n      <td>The song is an instrumental. The song is slow ...</td>\n      <td>D:\\TTM\\music_data\\zyXa2tdBTGc.wav</td>\n    </tr>\n    <tr>\n      <th>5520</th>\n      <td>This is a glitch music piece. There is a synth...</td>\n      <td>D:\\TTM\\music_data\\zzNdwF40ID8.wav</td>\n    </tr>\n  </tbody>\n</table>\n<p>5521 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption_wav_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T14:08:33.434477600Z",
     "start_time": "2024-03-31T14:08:33.413537600Z"
    }
   },
   "id": "656374bcfb7fa50d"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "caption_wav_df = caption_wav_df[:100]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T14:08:33.469877200Z",
     "start_time": "2024-03-31T14:08:33.430490Z"
    }
   },
   "id": "d4e8e677e7c93209"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "                                              caption  \\\n0   The low quality recording features a ballad so...   \n1   This song features an electric guitar as the m...   \n2   a male voice is singing a melody with changing...   \n3   This song contains digital drums playing a sim...   \n4   This song features a rubber instrument being p...   \n..                                                ...   \n95  This is a rock music piece playing in the back...   \n96  The low quality recording features a pop song ...   \n97  This composition contains an upright bass play...   \n98  An acoustic drum set is playing a 16th note rh...   \n99  The Soft Rock song features a passionate femal...   \n\n                             wav_path  \n0   D:\\TTM\\music_data\\-0Gj8-vB1q4.wav  \n1   D:\\TTM\\music_data\\-0SdAVK79lg.wav  \n2   D:\\TTM\\music_data\\-0vPFx-wRRI.wav  \n3   D:\\TTM\\music_data\\-0xzrMun0Rs.wav  \n4   D:\\TTM\\music_data\\-1LrH01Ei1w.wav  \n..                                ...  \n95  D:\\TTM\\music_data\\-taO6N-rxv4.wav  \n96  D:\\TTM\\music_data\\-tmY1GEH3_Y.wav  \n97  D:\\TTM\\music_data\\-tpq_bzSKes.wav  \n98  D:\\TTM\\music_data\\-uaTK8sa5Ms.wav  \n99  D:\\TTM\\music_data\\-v5hgCh3M2w.wav  \n\n[100 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>caption</th>\n      <th>wav_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The low quality recording features a ballad so...</td>\n      <td>D:\\TTM\\music_data\\-0Gj8-vB1q4.wav</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>This song features an electric guitar as the m...</td>\n      <td>D:\\TTM\\music_data\\-0SdAVK79lg.wav</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a male voice is singing a melody with changing...</td>\n      <td>D:\\TTM\\music_data\\-0vPFx-wRRI.wav</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>This song contains digital drums playing a sim...</td>\n      <td>D:\\TTM\\music_data\\-0xzrMun0Rs.wav</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>This song features a rubber instrument being p...</td>\n      <td>D:\\TTM\\music_data\\-1LrH01Ei1w.wav</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>This is a rock music piece playing in the back...</td>\n      <td>D:\\TTM\\music_data\\-taO6N-rxv4.wav</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>The low quality recording features a pop song ...</td>\n      <td>D:\\TTM\\music_data\\-tmY1GEH3_Y.wav</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>This composition contains an upright bass play...</td>\n      <td>D:\\TTM\\music_data\\-tpq_bzSKes.wav</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>An acoustic drum set is playing a 16th note rh...</td>\n      <td>D:\\TTM\\music_data\\-uaTK8sa5Ms.wav</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>The Soft Rock song features a passionate femal...</td>\n      <td>D:\\TTM\\music_data\\-v5hgCh3M2w.wav</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption_wav_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T14:08:33.539573600Z",
     "start_time": "2024-03-31T14:08:33.450437300Z"
    }
   },
   "id": "d691a2a4c482b047"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\tejas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tejas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "C:\\Users\\tejas\\AppData\\Local\\Temp\\ipykernel_21576\\478400242.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  caption_wav_df['processed_caption'] = caption_wav_df['caption'].apply(preprocess_text)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Get list of stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function for text preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# Apply text preprocessing to captions in the DataFrame\n",
    "caption_wav_df['processed_caption'] = caption_wav_df['caption'].apply(preprocess_text)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T14:08:37.526390400Z",
     "start_time": "2024-03-31T14:08:33.481817700Z"
    }
   },
   "id": "7d4e4bde86f9ed55"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "                                              caption  \\\n0   The low quality recording features a ballad so...   \n1   This song features an electric guitar as the m...   \n2   a male voice is singing a melody with changing...   \n3   This song contains digital drums playing a sim...   \n4   This song features a rubber instrument being p...   \n..                                                ...   \n95  This is a rock music piece playing in the back...   \n96  The low quality recording features a pop song ...   \n97  This composition contains an upright bass play...   \n98  An acoustic drum set is playing a 16th note rh...   \n99  The Soft Rock song features a passionate femal...   \n\n                             wav_path  \\\n0   D:\\TTM\\music_data\\-0Gj8-vB1q4.wav   \n1   D:\\TTM\\music_data\\-0SdAVK79lg.wav   \n2   D:\\TTM\\music_data\\-0vPFx-wRRI.wav   \n3   D:\\TTM\\music_data\\-0xzrMun0Rs.wav   \n4   D:\\TTM\\music_data\\-1LrH01Ei1w.wav   \n..                                ...   \n95  D:\\TTM\\music_data\\-taO6N-rxv4.wav   \n96  D:\\TTM\\music_data\\-tmY1GEH3_Y.wav   \n97  D:\\TTM\\music_data\\-tpq_bzSKes.wav   \n98  D:\\TTM\\music_data\\-uaTK8sa5Ms.wav   \n99  D:\\TTM\\music_data\\-v5hgCh3M2w.wav   \n\n                                    processed_caption  \n0   [low, quality, recording, features, ballad, so...  \n1   [song, features, electric, guitar, main, instr...  \n2   [male, voice, singing, melody, changing, tempo...  \n3   [song, contains, digital, drums, playing, simp...  \n4   [song, features, rubber, instrument, played, s...  \n..                                                ...  \n95  [rock, music, piece, playing, background, tuto...  \n96  [low, quality, recording, features, pop, song,...  \n97  [composition, contains, upright, bass, playing...  \n98  [acoustic, drum, set, playing, 16th, note, rhy...  \n99  [soft, rock, song, features, passionate, femal...  \n\n[100 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>caption</th>\n      <th>wav_path</th>\n      <th>processed_caption</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The low quality recording features a ballad so...</td>\n      <td>D:\\TTM\\music_data\\-0Gj8-vB1q4.wav</td>\n      <td>[low, quality, recording, features, ballad, so...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>This song features an electric guitar as the m...</td>\n      <td>D:\\TTM\\music_data\\-0SdAVK79lg.wav</td>\n      <td>[song, features, electric, guitar, main, instr...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a male voice is singing a melody with changing...</td>\n      <td>D:\\TTM\\music_data\\-0vPFx-wRRI.wav</td>\n      <td>[male, voice, singing, melody, changing, tempo...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>This song contains digital drums playing a sim...</td>\n      <td>D:\\TTM\\music_data\\-0xzrMun0Rs.wav</td>\n      <td>[song, contains, digital, drums, playing, simp...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>This song features a rubber instrument being p...</td>\n      <td>D:\\TTM\\music_data\\-1LrH01Ei1w.wav</td>\n      <td>[song, features, rubber, instrument, played, s...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>This is a rock music piece playing in the back...</td>\n      <td>D:\\TTM\\music_data\\-taO6N-rxv4.wav</td>\n      <td>[rock, music, piece, playing, background, tuto...</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>The low quality recording features a pop song ...</td>\n      <td>D:\\TTM\\music_data\\-tmY1GEH3_Y.wav</td>\n      <td>[low, quality, recording, features, pop, song,...</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>This composition contains an upright bass play...</td>\n      <td>D:\\TTM\\music_data\\-tpq_bzSKes.wav</td>\n      <td>[composition, contains, upright, bass, playing...</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>An acoustic drum set is playing a 16th note rh...</td>\n      <td>D:\\TTM\\music_data\\-uaTK8sa5Ms.wav</td>\n      <td>[acoustic, drum, set, playing, 16th, note, rhy...</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>The Soft Rock song features a passionate femal...</td>\n      <td>D:\\TTM\\music_data\\-v5hgCh3M2w.wav</td>\n      <td>[soft, rock, song, features, passionate, femal...</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption_wav_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T14:08:37.598287500Z",
     "start_time": "2024-03-31T14:08:37.540352300Z"
    }
   },
   "id": "a0f5d2fe6b37ccfa"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "0     [low, quality, recording, features, ballad, so...\n1     [song, features, electric, guitar, main, instr...\n2     [male, voice, singing, melody, changing, tempo...\n3     [song, contains, digital, drums, playing, simp...\n4     [song, features, rubber, instrument, played, s...\n                            ...                        \n95    [rock, music, piece, playing, background, tuto...\n96    [low, quality, recording, features, pop, song,...\n97    [composition, contains, upright, bass, playing...\n98    [acoustic, drum, set, playing, 16th, note, rhy...\n99    [soft, rock, song, features, passionate, femal...\nName: processed_caption, Length: 100, dtype: object"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption_wav_df['processed_caption']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T14:08:37.599284900Z",
     "start_time": "2024-03-31T14:08:37.560317800Z"
    }
   },
   "id": "b7cdf5fbfd25c892"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T14:08:37.600282900Z",
     "start_time": "2024-03-31T14:08:37.576272400Z"
    }
   },
   "id": "a87be5a448a7fb8a"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tejas\\AppData\\Local\\Temp\\ipykernel_21576\\1458204219.py:11: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(wav_path)\n",
      "D:\\Anaconda\\Anaconda_Installation\\envs\\new_env\\lib\\site-packages\\librosa\\core\\audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found: D:\\TTM\\music_data\\-sevczF5etI.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tejas\\AppData\\Local\\Temp\\ipykernel_21576\\1458204219.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  caption_wav_df['specto_path'] = caption_wav_df['wav_path'].apply(lambda x: convert_to_spectrogram(x, specto_folder))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to convert WAV files to spectrograms and save images\n",
    "def convert_to_spectrogram(wav_path, specto_folder):\n",
    "    # Load the audio file\n",
    "    try:\n",
    "        y, sr = librosa.load(wav_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {wav_path}\")\n",
    "        return None\n",
    "    \n",
    "    # Compute the spectrogram\n",
    "    spectrogram = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "    db_spectrogram = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "    \n",
    "    # Save the spectrogram image\n",
    "    specto_path = os.path.join(specto_folder, '-'+os.path.basename(wav_path).replace('.wav', '.png'))\n",
    "    plt.imsave(specto_path, db_spectrogram, cmap='viridis', format='png')\n",
    "    \n",
    "    return specto_path\n",
    "\n",
    "# Create a folder for spectrograms if it doesn't exist\n",
    "specto_folder = 'specto2'\n",
    "if not os.path.exists(specto_folder):\n",
    "    os.makedirs(specto_folder)\n",
    "\n",
    "# Apply the function to each WAV file and store the paths\n",
    "caption_wav_df['specto_path'] = caption_wav_df['wav_path'].apply(lambda x: convert_to_spectrogram(x, specto_folder))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T14:09:08.817923600Z",
     "start_time": "2024-03-31T14:08:53.700470400Z"
    }
   },
   "id": "15b41e7cad73e086"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "                                              caption  \\\n0   The low quality recording features a ballad so...   \n1   This song features an electric guitar as the m...   \n2   a male voice is singing a melody with changing...   \n3   This song contains digital drums playing a sim...   \n4   This song features a rubber instrument being p...   \n..                                                ...   \n95  This is a rock music piece playing in the back...   \n96  The low quality recording features a pop song ...   \n97  This composition contains an upright bass play...   \n98  An acoustic drum set is playing a 16th note rh...   \n99  The Soft Rock song features a passionate femal...   \n\n                             wav_path  \\\n0   D:\\TTM\\music_data\\-0Gj8-vB1q4.wav   \n1   D:\\TTM\\music_data\\-0SdAVK79lg.wav   \n2   D:\\TTM\\music_data\\-0vPFx-wRRI.wav   \n3   D:\\TTM\\music_data\\-0xzrMun0Rs.wav   \n4   D:\\TTM\\music_data\\-1LrH01Ei1w.wav   \n..                                ...   \n95  D:\\TTM\\music_data\\-taO6N-rxv4.wav   \n96  D:\\TTM\\music_data\\-tmY1GEH3_Y.wav   \n97  D:\\TTM\\music_data\\-tpq_bzSKes.wav   \n98  D:\\TTM\\music_data\\-uaTK8sa5Ms.wav   \n99  D:\\TTM\\music_data\\-v5hgCh3M2w.wav   \n\n                                    processed_caption  \\\n0   [low, quality, recording, features, ballad, so...   \n1   [song, features, electric, guitar, main, instr...   \n2   [male, voice, singing, melody, changing, tempo...   \n3   [song, contains, digital, drums, playing, simp...   \n4   [song, features, rubber, instrument, played, s...   \n..                                                ...   \n95  [rock, music, piece, playing, background, tuto...   \n96  [low, quality, recording, features, pop, song,...   \n97  [composition, contains, upright, bass, playing...   \n98  [acoustic, drum, set, playing, 16th, note, rhy...   \n99  [soft, rock, song, features, passionate, femal...   \n\n                 specto_path  \n0   specto2\\--0Gj8-vB1q4.png  \n1   specto2\\--0SdAVK79lg.png  \n2   specto2\\--0vPFx-wRRI.png  \n3   specto2\\--0xzrMun0Rs.png  \n4   specto2\\--1LrH01Ei1w.png  \n..                       ...  \n95  specto2\\--taO6N-rxv4.png  \n96  specto2\\--tmY1GEH3_Y.png  \n97  specto2\\--tpq_bzSKes.png  \n98  specto2\\--uaTK8sa5Ms.png  \n99  specto2\\--v5hgCh3M2w.png  \n\n[100 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>caption</th>\n      <th>wav_path</th>\n      <th>processed_caption</th>\n      <th>specto_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The low quality recording features a ballad so...</td>\n      <td>D:\\TTM\\music_data\\-0Gj8-vB1q4.wav</td>\n      <td>[low, quality, recording, features, ballad, so...</td>\n      <td>specto2\\--0Gj8-vB1q4.png</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>This song features an electric guitar as the m...</td>\n      <td>D:\\TTM\\music_data\\-0SdAVK79lg.wav</td>\n      <td>[song, features, electric, guitar, main, instr...</td>\n      <td>specto2\\--0SdAVK79lg.png</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a male voice is singing a melody with changing...</td>\n      <td>D:\\TTM\\music_data\\-0vPFx-wRRI.wav</td>\n      <td>[male, voice, singing, melody, changing, tempo...</td>\n      <td>specto2\\--0vPFx-wRRI.png</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>This song contains digital drums playing a sim...</td>\n      <td>D:\\TTM\\music_data\\-0xzrMun0Rs.wav</td>\n      <td>[song, contains, digital, drums, playing, simp...</td>\n      <td>specto2\\--0xzrMun0Rs.png</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>This song features a rubber instrument being p...</td>\n      <td>D:\\TTM\\music_data\\-1LrH01Ei1w.wav</td>\n      <td>[song, features, rubber, instrument, played, s...</td>\n      <td>specto2\\--1LrH01Ei1w.png</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>This is a rock music piece playing in the back...</td>\n      <td>D:\\TTM\\music_data\\-taO6N-rxv4.wav</td>\n      <td>[rock, music, piece, playing, background, tuto...</td>\n      <td>specto2\\--taO6N-rxv4.png</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>The low quality recording features a pop song ...</td>\n      <td>D:\\TTM\\music_data\\-tmY1GEH3_Y.wav</td>\n      <td>[low, quality, recording, features, pop, song,...</td>\n      <td>specto2\\--tmY1GEH3_Y.png</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>This composition contains an upright bass play...</td>\n      <td>D:\\TTM\\music_data\\-tpq_bzSKes.wav</td>\n      <td>[composition, contains, upright, bass, playing...</td>\n      <td>specto2\\--tpq_bzSKes.png</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>An acoustic drum set is playing a 16th note rh...</td>\n      <td>D:\\TTM\\music_data\\-uaTK8sa5Ms.wav</td>\n      <td>[acoustic, drum, set, playing, 16th, note, rhy...</td>\n      <td>specto2\\--uaTK8sa5Ms.png</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>The Soft Rock song features a passionate femal...</td>\n      <td>D:\\TTM\\music_data\\-v5hgCh3M2w.wav</td>\n      <td>[soft, rock, song, features, passionate, femal...</td>\n      <td>specto2\\--v5hgCh3M2w.png</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption_wav_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T14:09:08.891824200Z",
     "start_time": "2024-03-31T14:09:08.820933500Z"
    }
   },
   "id": "f3ca42094c77774e"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "caption_wav_df = caption_wav_df.dropna(subset=['specto_path'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T14:09:08.910938800Z",
     "start_time": "2024-03-31T14:09:08.852097600Z"
    }
   },
   "id": "bbc3f6c7b9c6cd80"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "                                              caption  \\\n0   The low quality recording features a ballad so...   \n1   This song features an electric guitar as the m...   \n2   a male voice is singing a melody with changing...   \n3   This song contains digital drums playing a sim...   \n4   This song features a rubber instrument being p...   \n..                                                ...   \n95  This is a rock music piece playing in the back...   \n96  The low quality recording features a pop song ...   \n97  This composition contains an upright bass play...   \n98  An acoustic drum set is playing a 16th note rh...   \n99  The Soft Rock song features a passionate femal...   \n\n                             wav_path  \\\n0   D:\\TTM\\music_data\\-0Gj8-vB1q4.wav   \n1   D:\\TTM\\music_data\\-0SdAVK79lg.wav   \n2   D:\\TTM\\music_data\\-0vPFx-wRRI.wav   \n3   D:\\TTM\\music_data\\-0xzrMun0Rs.wav   \n4   D:\\TTM\\music_data\\-1LrH01Ei1w.wav   \n..                                ...   \n95  D:\\TTM\\music_data\\-taO6N-rxv4.wav   \n96  D:\\TTM\\music_data\\-tmY1GEH3_Y.wav   \n97  D:\\TTM\\music_data\\-tpq_bzSKes.wav   \n98  D:\\TTM\\music_data\\-uaTK8sa5Ms.wav   \n99  D:\\TTM\\music_data\\-v5hgCh3M2w.wav   \n\n                                    processed_caption  \\\n0   [low, quality, recording, features, ballad, so...   \n1   [song, features, electric, guitar, main, instr...   \n2   [male, voice, singing, melody, changing, tempo...   \n3   [song, contains, digital, drums, playing, simp...   \n4   [song, features, rubber, instrument, played, s...   \n..                                                ...   \n95  [rock, music, piece, playing, background, tuto...   \n96  [low, quality, recording, features, pop, song,...   \n97  [composition, contains, upright, bass, playing...   \n98  [acoustic, drum, set, playing, 16th, note, rhy...   \n99  [soft, rock, song, features, passionate, femal...   \n\n                 specto_path  \n0   specto2\\--0Gj8-vB1q4.png  \n1   specto2\\--0SdAVK79lg.png  \n2   specto2\\--0vPFx-wRRI.png  \n3   specto2\\--0xzrMun0Rs.png  \n4   specto2\\--1LrH01Ei1w.png  \n..                       ...  \n95  specto2\\--taO6N-rxv4.png  \n96  specto2\\--tmY1GEH3_Y.png  \n97  specto2\\--tpq_bzSKes.png  \n98  specto2\\--uaTK8sa5Ms.png  \n99  specto2\\--v5hgCh3M2w.png  \n\n[99 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>caption</th>\n      <th>wav_path</th>\n      <th>processed_caption</th>\n      <th>specto_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The low quality recording features a ballad so...</td>\n      <td>D:\\TTM\\music_data\\-0Gj8-vB1q4.wav</td>\n      <td>[low, quality, recording, features, ballad, so...</td>\n      <td>specto2\\--0Gj8-vB1q4.png</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>This song features an electric guitar as the m...</td>\n      <td>D:\\TTM\\music_data\\-0SdAVK79lg.wav</td>\n      <td>[song, features, electric, guitar, main, instr...</td>\n      <td>specto2\\--0SdAVK79lg.png</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a male voice is singing a melody with changing...</td>\n      <td>D:\\TTM\\music_data\\-0vPFx-wRRI.wav</td>\n      <td>[male, voice, singing, melody, changing, tempo...</td>\n      <td>specto2\\--0vPFx-wRRI.png</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>This song contains digital drums playing a sim...</td>\n      <td>D:\\TTM\\music_data\\-0xzrMun0Rs.wav</td>\n      <td>[song, contains, digital, drums, playing, simp...</td>\n      <td>specto2\\--0xzrMun0Rs.png</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>This song features a rubber instrument being p...</td>\n      <td>D:\\TTM\\music_data\\-1LrH01Ei1w.wav</td>\n      <td>[song, features, rubber, instrument, played, s...</td>\n      <td>specto2\\--1LrH01Ei1w.png</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>This is a rock music piece playing in the back...</td>\n      <td>D:\\TTM\\music_data\\-taO6N-rxv4.wav</td>\n      <td>[rock, music, piece, playing, background, tuto...</td>\n      <td>specto2\\--taO6N-rxv4.png</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>The low quality recording features a pop song ...</td>\n      <td>D:\\TTM\\music_data\\-tmY1GEH3_Y.wav</td>\n      <td>[low, quality, recording, features, pop, song,...</td>\n      <td>specto2\\--tmY1GEH3_Y.png</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>This composition contains an upright bass play...</td>\n      <td>D:\\TTM\\music_data\\-tpq_bzSKes.wav</td>\n      <td>[composition, contains, upright, bass, playing...</td>\n      <td>specto2\\--tpq_bzSKes.png</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>An acoustic drum set is playing a 16th note rh...</td>\n      <td>D:\\TTM\\music_data\\-uaTK8sa5Ms.wav</td>\n      <td>[acoustic, drum, set, playing, 16th, note, rhy...</td>\n      <td>specto2\\--uaTK8sa5Ms.png</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>The Soft Rock song features a passionate femal...</td>\n      <td>D:\\TTM\\music_data\\-v5hgCh3M2w.wav</td>\n      <td>[soft, rock, song, features, passionate, femal...</td>\n      <td>specto2\\--v5hgCh3M2w.png</td>\n    </tr>\n  </tbody>\n</table>\n<p>99 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caption_wav_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T14:09:08.985126200Z",
     "start_time": "2024-03-31T14:09:08.867608100Z"
    }
   },
   "id": "1d58c810d8de62d1"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (861, 128)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Load the image\n",
    "image_path = r'D:\\TTM\\specto2\\--0Gj8-vB1q4.png'\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Get the shape of the image\n",
    "image_shape = image.size  # This returns width, height\n",
    "\n",
    "print(\"Image shape:\", image_shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T14:12:51.911576100Z",
     "start_time": "2024-03-31T14:12:51.898578300Z"
    }
   },
   "id": "af0880d942363dc5"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "max_caption_length = max(len(caption.split()) for caption in caption_wav_df['caption'])\n",
    "input_shape = image_shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T14:13:23.601379100Z",
     "start_time": "2024-03-31T14:13:23.584424300Z"
    }
   },
   "id": "c04b87e00a25715f"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "104"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_caption_length"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T14:13:28.451925100Z",
     "start_time": "2024-03-31T14:13:28.436733100Z"
    }
   },
   "id": "a74057d0a49e7a3e"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The total size of the tensor must be unchanged. Received: input_shape=(512,), target_shape=(861, 128)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[26], line 60\u001B[0m\n\u001B[0;32m     57\u001B[0m input_shape \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m861\u001B[39m, \u001B[38;5;241m128\u001B[39m)  \u001B[38;5;66;03m# Use the determined image shape\u001B[39;00m\n\u001B[0;32m     59\u001B[0m \u001B[38;5;66;03m# Build and compile the generator and discriminator models\u001B[39;00m\n\u001B[1;32m---> 60\u001B[0m generator \u001B[38;5;241m=\u001B[39m \u001B[43mbuild_generator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlatent_dim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaption_shape\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     61\u001B[0m discriminator \u001B[38;5;241m=\u001B[39m build_discriminator(input_shape, caption_shape)\n\u001B[0;32m     63\u001B[0m discriminator\u001B[38;5;241m.\u001B[39mcompile(loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbinary_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m, optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madam\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[1;32mIn[26], line 18\u001B[0m, in \u001B[0;36mbuild_generator\u001B[1;34m(latent_dim, caption_shape)\u001B[0m\n\u001B[0;32m     15\u001B[0m x \u001B[38;5;241m=\u001B[39m layers\u001B[38;5;241m.\u001B[39mDense(\u001B[38;5;241m512\u001B[39m, activation\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrelu\u001B[39m\u001B[38;5;124m'\u001B[39m)(x)\n\u001B[0;32m     17\u001B[0m \u001B[38;5;66;03m# Reshape\u001B[39;00m\n\u001B[1;32m---> 18\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[43mlayers\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mReshape\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m861\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m128\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Assuming input shape is (861, 128)\u001B[39;00m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;66;03m# Output layer\u001B[39;00m\n\u001B[0;32m     21\u001B[0m output \u001B[38;5;241m=\u001B[39m layers\u001B[38;5;241m.\u001B[39mConv1DTranspose(\u001B[38;5;241m1\u001B[39m, kernel_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m7\u001B[39m, strides\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, padding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msame\u001B[39m\u001B[38;5;124m'\u001B[39m, activation\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtanh\u001B[39m\u001B[38;5;124m'\u001B[39m)(x)\n",
      "File \u001B[1;32mD:\\Anaconda\\Anaconda_Installation\\envs\\new_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m    120\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m    121\u001B[0m     \u001B[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m--> 122\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    123\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    124\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32mD:\\Anaconda\\Anaconda_Installation\\envs\\new_env\\lib\\site-packages\\keras\\src\\ops\\operation_utils.py:302\u001B[0m, in \u001B[0;36mcompute_reshape_output_shape\u001B[1;34m(input_shape, newshape, newshape_arg_name)\u001B[0m\n\u001B[0;32m    300\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m unknown_dim_count \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    301\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m input_size \u001B[38;5;241m!=\u001B[39m math\u001B[38;5;241m.\u001B[39mprod(newshape):\n\u001B[1;32m--> 302\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    303\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe total size of the tensor must be unchanged. Received: \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    304\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_shape=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00minput_shape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnewshape_arg_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnewshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    305\u001B[0m         )\n\u001B[0;32m    306\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m newshape\n\u001B[0;32m    308\u001B[0m \u001B[38;5;66;03m# We have one -1 in `newshape`, compute the actual value\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: The total size of the tensor must be unchanged. Received: input_shape=(512,), target_shape=(861, 128)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define the Generator model\n",
    "def build_generator(latent_dim, caption_shape):\n",
    "    noise_input = layers.Input(shape=(latent_dim,))\n",
    "    caption_input = layers.Input(shape=caption_shape)\n",
    "    \n",
    "    # Concatenate noise and caption inputs\n",
    "    concatenated_input = layers.Concatenate()([noise_input, caption_input])\n",
    "    \n",
    "    # Dense layers\n",
    "    x = layers.Dense(128, activation='relu')(concatenated_input)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    \n",
    "    # Reshape\n",
    "    x = layers.Reshape((861, 128))(x)  # Assuming input shape is (861, 128)\n",
    "    \n",
    "    # Output layer\n",
    "    output = layers.Conv1DTranspose(1, kernel_size=7, strides=1, padding='same', activation='tanh')(x)\n",
    "    \n",
    "    # Define model\n",
    "    model = models.Model(inputs=[noise_input, caption_input], outputs=output)\n",
    "    return model\n",
    "\n",
    "# Define the Discriminator model\n",
    "def build_discriminator(input_shape, caption_shape):\n",
    "    audio_input = layers.Input(shape=input_shape)\n",
    "    caption_input = layers.Input(shape=caption_shape)\n",
    "    \n",
    "    # Concatenate the audio input and caption input\n",
    "    concatenated_input = layers.Concatenate()([audio_input, caption_input])\n",
    "    \n",
    "    # Flatten the input\n",
    "    x = layers.Flatten()(concatenated_input)\n",
    "    \n",
    "    # Dense layers\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    \n",
    "    # Output layer\n",
    "    output = layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    # Define model\n",
    "    model = models.Model(inputs=[audio_input, caption_input], outputs=output)\n",
    "    return model\n",
    "\n",
    "# Define the size of the noise vector\n",
    "latent_dim = 100\n",
    "\n",
    "# Define the shapes of the caption inputs\n",
    "caption_shape = (104,)  # Use the determined max_caption_length\n",
    "\n",
    "# Define the input shape for the spectrogram data\n",
    "input_shape = (861, 128)  # Use the determined image shape\n",
    "\n",
    "# Build and compile the generator and discriminator models\n",
    "generator = build_generator(latent_dim, caption_shape)\n",
    "discriminator = build_discriminator(input_shape, caption_shape)\n",
    "\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "discriminator.trainable = False\n",
    "\n",
    "# Define the combined model (GAN)\n",
    "noise_input = layers.Input(shape=(latent_dim,))\n",
    "caption_input = layers.Input(shape=caption_shape)\n",
    "generated_audio = generator([noise_input, caption_input])\n",
    "validity = discriminator([generated_audio, caption_input])\n",
    "\n",
    "gan = models.Model(inputs=[noise_input, caption_input], outputs=validity)\n",
    "gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "# Display model architectures\n",
    "generator.summary()\n",
    "discriminator.summary()\n",
    "gan.summary()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T14:42:18.278081500Z",
     "start_time": "2024-03-31T14:42:18.180388600Z"
    }
   },
   "id": "b09f60073708b0f9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    ";import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# Define the size of the noise vector\n",
    "latent_dim = 100\n",
    "\n",
    "# Define the shapes of the caption inputs\n",
    "caption_shape = (max_caption_length,)\n",
    "\n",
    "# Define the training hyperparameters\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "learning_rate = 0.0002\n",
    "beta_1 = 0.5\n",
    "\n",
    "# Define the binary crossentropy loss function\n",
    "binary_crossentropy = BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = Adam(learning_rate, beta_1)\n",
    "\n",
    "# Define the generator and discriminator models\n",
    "generator = build_generator(latent_dim, caption_shape)\n",
    "discriminator = build_discriminator(input_shape, caption_shape)\n",
    "\n",
    "# Compile the discriminator\n",
    "discriminator.compile(optimizer=optimizer, loss=binary_crossentropy)\n",
    "\n",
    "# Define the combined model (GAN)\n",
    "noise_input = layers.Input(shape=(latent_dim,))\n",
    "caption_input = layers.Input(shape=caption_shape)\n",
    "generated_audio = generator([noise_input, caption_input])\n",
    "validity = discriminator([generated_audio, caption_input])\n",
    "\n",
    "gan = models.Model(inputs=[noise_input, caption_input], outputs=validity)\n",
    "gan.compile(optimizer=optimizer, loss=binary_crossentropy)\n",
    "\n",
    "# Plot the generator and discriminator models\n",
    "plot_model(generator, to_file='generator.png', show_shapes=True, show_layer_names=True)\n",
    "plot_model(discriminator, to_file='discriminator.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "# Training loop\n",
    "num_batches = len(caption_wav_df) // batch_size\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx in range(num_batches):\n",
    "        # Select a random batch of caption and audio samples\n",
    "        batch_indices = np.random.choice(len(caption_wav_df), size=batch_size, replace=False)\n",
    "        batch_captions = caption_wav_df['processed_caption'].iloc[batch_indices]\n",
    "        batch_audio = load_audio_batch(caption_wav_df['wav_path'].iloc[batch_indices])\n",
    "        \n",
    "        # Generate a batch of random noise\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        \n",
    "        # Generate fake audio samples using the generator\n",
    "        generated_audio = generator.predict([noise, batch_captions])\n",
    "        \n",
    "        # Train the discriminator\n",
    "        real_labels = np.ones((batch_size, 1))\n",
    "        fake_labels = np.zeros((batch_size, 1))\n",
    "        \n",
    "        d_loss_real = discriminator.train_on_batch([batch_audio, batch_captions], real_labels)\n",
    "        d_loss_fake = discriminator.train_on_batch([generated_audio, batch_captions], fake_labels)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "        \n",
    "        # Train the generator\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        g_loss = gan.train_on_batch([noise, batch_captions], real_labels)\n",
    "        \n",
    "        # Print progress\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Batch {batch_idx+1}/{num_batches}, D Loss: {d_loss}, G Loss: {g_loss}\")\n",
    "\n",
    "    # Save models\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        generator.save(f'generator_epoch_{epoch+1}.h5')\n",
    "        discriminator.save(f'discriminator_epoch_{epoch+1}.h5')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d06225cd5d5fa87"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "51182b71c25ef14c"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(861, 128)\n",
      "(104,)\n"
     ]
    }
   ],
   "source": [
    "imgs = image_shape\n",
    "capt = caption_shape\n",
    "print(imgs)\n",
    "print(capt)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T14:52:02.595461700Z",
     "start_time": "2024-03-31T14:52:02.545563200Z"
    }
   },
   "id": "a04ff14bd0bec348"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A `Concatenate` layer requires inputs with matching shapes except for the concatenation axis. Received: input_shape=[(None, 861, 128), (None, 104)]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[28], line 10\u001B[0m\n\u001B[0;32m      7\u001B[0m input2 \u001B[38;5;241m=\u001B[39m Input(shape\u001B[38;5;241m=\u001B[39mcapt)\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m# Concatenate the layers\u001B[39;00m\n\u001B[1;32m---> 10\u001B[0m concatenated_layer \u001B[38;5;241m=\u001B[39m \u001B[43mConcatenate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43minput1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput2\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m# Output layer\u001B[39;00m\n\u001B[0;32m     13\u001B[0m output \u001B[38;5;241m=\u001B[39m Dense(\u001B[38;5;241m1\u001B[39m, activation\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msigmoid\u001B[39m\u001B[38;5;124m'\u001B[39m)(concatenated_layer)\n",
      "File \u001B[1;32mD:\\Anaconda\\Anaconda_Installation\\envs\\new_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m    120\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m    121\u001B[0m     \u001B[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m--> 122\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    123\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    124\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32mD:\\Anaconda\\Anaconda_Installation\\envs\\new_env\\lib\\site-packages\\keras\\src\\layers\\merging\\concatenate.py:85\u001B[0m, in \u001B[0;36mConcatenate.build\u001B[1;34m(self, input_shape)\u001B[0m\n\u001B[0;32m     83\u001B[0m ranks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m(\u001B[38;5;28mlen\u001B[39m(shape) \u001B[38;5;28;01mfor\u001B[39;00m shape \u001B[38;5;129;01min\u001B[39;00m shape_set)\n\u001B[0;32m     84\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(ranks) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m---> 85\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(err_msg)\n\u001B[0;32m     86\u001B[0m \u001B[38;5;66;03m# Get the only rank for the set.\u001B[39;00m\n\u001B[0;32m     87\u001B[0m (rank,) \u001B[38;5;241m=\u001B[39m ranks\n",
      "\u001B[1;31mValueError\u001B[0m: A `Concatenate` layer requires inputs with matching shapes except for the concatenation axis. Received: input_shape=[(None, 861, 128), (None, 104)]"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Concatenate, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Define inputs\n",
    "input1 = Input(shape=imgs)\n",
    "input2 = Input(shape=capt)\n",
    "\n",
    "# Concatenate the layers\n",
    "concatenated_layer = Concatenate()([input1, input2])\n",
    "\n",
    "# Output layer\n",
    "output = Dense(1, activation='sigmoid')(concatenated_layer)\n",
    "\n",
    "# Create model\n",
    "model = Model(inputs=[input1, input2], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T14:53:58.042127100Z",
     "start_time": "2024-03-31T14:53:57.946412500Z"
    }
   },
   "id": "9f2a67d4b4d0c20b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1e5c0185bfe6c8d3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "tensorflow",
   "language": "python",
   "display_name": "Python 3.9 (tensorflow)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
